{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.generators.degree_seq import random_degree_sequence_graph\n",
    "from networkx.algorithms.graphical import is_graphical\n",
    "from networkx.utils.random_sequence import powerlaw_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('../figures/norm.mplstyle')\n",
    "from ldpc.code_util import *\n",
    "from ldpc.mod2 import *\n",
    "from bposd.hgp import hgp\n",
    "from bposd.css import css_code, compute_code_distance\n",
    "import sys, os\n",
    "from timeit import default_timer as timer\n",
    "import cairo\n",
    "import cmath\n",
    "\n",
    "def read_pc(filepath):\n",
    "    \"\"\"\n",
    "    Read parity check matrix from file.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    pc = []\n",
    "    for line in lines:\n",
    "        row = [int(x) for x in line.split()]\n",
    "        pc.append(row)\n",
    "    return np.array(pc, dtype=np.uint8)\n",
    "\n",
    "def get_classical_code_distance(h):\n",
    "    if rank(h) == h.shape[1]:\n",
    "        print('Code is full rank, no codewords')\n",
    "        return np.inf\n",
    "    else:\n",
    "        start = timer()\n",
    "        print('Code is not full rank, there are codewords')\n",
    "        print('Computing codeword space basis ...')\n",
    "        ker = nullspace(h)\n",
    "        print('debug: ker = ', ker)\n",
    "        end = timer()\n",
    "        print(f'Elapsed time for computing codeword space basis: {end-start} seconds', flush=True)\n",
    "        print('len of ker: ', len(ker))\n",
    "        print('Start finding minimum Hamming weight while buiding codeword space ...')\n",
    "        start = end\n",
    "        # @jit\n",
    "        def find_min_weight_while_build(matrix):\n",
    "            span = []\n",
    "            min_hamming_weight = np.inf\n",
    "            for ir, row in enumerate(matrix):\n",
    "                print('debug: ir = ', ir, 'current min_hamming_weight = ', min_hamming_weight, flush=True)  # debug\n",
    "                row_hamming_weight = np.sum(row)\n",
    "                if row_hamming_weight < min_hamming_weight:\n",
    "                    min_hamming_weight = row_hamming_weight\n",
    "                temp = [row]\n",
    "                for element in span:\n",
    "                    newvec = (row + element) % 2\n",
    "                    temp.append(newvec)\n",
    "                    newvec_hamming_weight = np.sum(newvec)\n",
    "                    if newvec_hamming_weight < min_hamming_weight:\n",
    "                        min_hamming_weight = newvec_hamming_weight\n",
    "                span = list(np.unique(temp + span, axis=0))\n",
    "            assert len(span) == 2**len(matrix) - 1\n",
    "            return min_hamming_weight\n",
    "        min_hamming_weight = find_min_weight_while_build(ker)\n",
    "        end = timer()\n",
    "        print(f'Elapsed time for finding minimum Hamming weight while buiding codeword space : {end-start} seconds', flush=True)\n",
    "        \n",
    "        return min_hamming_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_color_brightness(rgb, factor):\n",
    "    return tuple(min(255, int(c * factor)) for c in rgb)\n",
    "# Function to convert HEX to RGB\n",
    "def hex_to_rgb(value):\n",
    "    value = value.lstrip('#')\n",
    "    lv = len(value)\n",
    "    return tuple(int(value[i:i + lv // 3], 16) for i in range(0, lv, lv // 3))\n",
    "\n",
    "blue_hex = '#6167AF'\n",
    "blue_rgb = hex_to_rgb(blue_hex)\n",
    "# Generate gradient colors\n",
    "blues_grad = [adjust_color_brightness(blue_rgb, 1 + i * 0.8) for i in range(2)]\n",
    "# Convert RGB back to HEX for plotting\n",
    "blues_hex = ['#' + ''.join(f'{c:02x}' for c in color) for color in blues_grad]\n",
    "\n",
    "red_hex = '#F15B5B'\n",
    "red_rgb = hex_to_rgb(red_hex)\n",
    "# Generate gradient colors\n",
    "reds_grad = [adjust_color_brightness(red_rgb, 1 + i * 0.6) for i in range(3)]\n",
    "# Convert RGB back to HEX for plotting\n",
    "reds_hex = ['#' + ''.join(f'{c:02x}' for c in color) for color in reds_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate = 0.2\n",
    "namples = 100\n",
    "rng = np.random.default_rng(0)\n",
    "start = 1\n",
    "end = -1\n",
    "step = 3\n",
    "############################################################################################################\n",
    "# global settings\n",
    "############################################################################################################\n",
    "\n",
    "deglo = 5\n",
    "degup = 7\n",
    "seeds = range(21)\n",
    "noprledge = True\n",
    "noselfloop = True\n",
    "\n",
    "def sample_logical_ops(logical_basis, nsamples_logical):\n",
    "    rng = np.random.default_rng(0)\n",
    "    k = logical_basis.shape[0]\n",
    "    logical_ops = np.zeros((nsamples_logical, logical_basis.shape[1]), dtype=int)\n",
    "    # sample size_logicals logical operators, each of which is a linear combination of logical_basis\n",
    "    for i in range(nsamples_logical):\n",
    "        while True:\n",
    "            coeffs = rng.choice([0, 1], size=k).reshape(1, -1)\n",
    "            if not np.all(coeffs==0):\n",
    "                break\n",
    "        logical_ops[i] = np.mod(coeffs@logical_basis, 2)\n",
    "    return logical_ops\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "n = 300\n",
    "error_weights_full = []\n",
    "synd_weights_min_full = []\n",
    "for seed in seeds:\n",
    "    readdir = '/Users/yitan/Google Drive/My Drive/from_cannon/qmemory_simulation/data/laplacian_code'\n",
    "    readname = f'hclassical_configurationmodel_n={n}_deglo={deglo}_degup={degup}_noprledge={noprledge}_noselfloop={noselfloop}_seed={seed}.txt'\n",
    "    h = read_pc(os.path.join(readdir, readname))\n",
    "    logical_basis = nullspace(h)\n",
    "    logical_ops = sample_logical_ops(logical_basis, nsamples_logical=1)\n",
    "    logical_op = logical_ops[0]\n",
    "    posones_logical = np.where(logical_op==1)[0]\n",
    "    error_weights = np.arange(0, int(truncate*n)+1, 1)\n",
    "    # error_weights = np.arange(0, len(posones_logical)+1, 1)\n",
    "    synd_weights_list = []\n",
    "    for error_weight in error_weights:\n",
    "        error_vecs = np.zeros((nsamples, h.shape[1]), dtype=int)\n",
    "        for i in range(nsamples):\n",
    "            posones_error = rng.choice(posones_logical, size=error_weight, replace=False)\n",
    "            error_vecs[i, posones_error] = 1\n",
    "        synd_vecs = np.mod(error_vecs@(h.T), 2)\n",
    "        synd_weights = np.sum(synd_vecs, axis=1)\n",
    "        synd_weights_list.append(synd_weights)\n",
    "    synd_weights_list = np.array(synd_weights_list)\n",
    "    synd_weights_min = np.min(synd_weights_list, axis=1)\n",
    "    # num_half = int(len(synd_weights_min)/2)\n",
    "    # error_weights = error_weights[:num_half]\n",
    "    # synd_weights_min = synd_weights_min[:num_half]\n",
    "    error_weights_full.append(error_weights)\n",
    "    synd_weights_min_full.append(synd_weights_min)\n",
    "max_error_weight = np.max([error_weights[-1] for error_weights in error_weights_full])\n",
    "synd_weight_min_avg = np.zeros(max_error_weight+1)\n",
    "for error_weight in range(max_error_weight+1):\n",
    "    nonzero_synd_weights = []\n",
    "    for i in range(len(seeds)):\n",
    "        if error_weight < len(error_weights_full[i]):\n",
    "            nonzero_synd_weights.append(synd_weights_min_full[i][error_weight])\n",
    "    synd_weight_min_avg[error_weight] = np.mean(nonzero_synd_weights)\n",
    "ax.scatter(np.arange(max_error_weight+1)[start:end:step] / n, synd_weight_min_avg[start:end:step] / n, c=reds_hex[-1], edgecolors='k', zorder=10)\n",
    "# ax1.plot(np.arange(max_error_weight+1) / n, synd_weight_min_avg / n, '--', color='gray')\n",
    "\n",
    "\n",
    "n = 500\n",
    "error_weights_full = []\n",
    "synd_weights_min_full = []\n",
    "for seed in seeds:\n",
    "    readdir = '/Users/yitan/Google Drive/My Drive/from_cannon/qmemory_simulation/data/laplacian_code'\n",
    "    readname = f'hclassical_configurationmodel_n={n}_deglo={deglo}_degup={degup}_noprledge={noprledge}_noselfloop={noselfloop}_seed={seed}.txt'\n",
    "    h = read_pc(os.path.join(readdir, readname))\n",
    "    logical_basis = nullspace(h)\n",
    "    logical_ops = sample_logical_ops(logical_basis, nsamples_logical=1)\n",
    "    logical_op = logical_ops[0]\n",
    "    posones_logical = np.where(logical_op==1)[0]\n",
    "    error_weights = np.arange(0, int(truncate*n)+1, 1)\n",
    "    # error_weights = np.arange(0, len(posones_logical)+1, 1)\n",
    "    synd_weights_list = []\n",
    "    for error_weight in error_weights:\n",
    "        error_vecs = np.zeros((nsamples, h.shape[1]), dtype=int)\n",
    "        for i in range(nsamples):\n",
    "            posones_error = rng.choice(posones_logical, size=error_weight, replace=False)\n",
    "            error_vecs[i, posones_error] = 1\n",
    "        synd_vecs = np.mod(error_vecs@(h.T), 2)\n",
    "        synd_weights = np.sum(synd_vecs, axis=1)\n",
    "        synd_weights_list.append(synd_weights)\n",
    "    synd_weights_list = np.array(synd_weights_list)\n",
    "    synd_weights_min = np.min(synd_weights_list, axis=1)\n",
    "    # num_half = int(len(synd_weights_min)/2)\n",
    "    # error_weights = error_weights[:num_half]\n",
    "    # synd_weights_min = synd_weights_min[:num_half]\n",
    "    error_weights_full.append(error_weights)\n",
    "    synd_weights_min_full.append(synd_weights_min)\n",
    "max_error_weight = np.max([error_weights[-1] for error_weights in error_weights_full])\n",
    "synd_weight_min_avg = np.zeros(max_error_weight+1)\n",
    "for error_weight in range(max_error_weight+1):\n",
    "    nonzero_synd_weights = []\n",
    "    for i in range(len(seeds)):\n",
    "        if error_weight < len(error_weights_full[i]):\n",
    "            nonzero_synd_weights.append(synd_weights_min_full[i][error_weight])\n",
    "    synd_weight_min_avg[error_weight] = np.mean(nonzero_synd_weights)\n",
    "ax.scatter(np.arange(max_error_weight+1)[start:end:step] / n, synd_weight_min_avg[start:end:step] / n, c=reds_hex[-2], edgecolors='k', zorder=10)\n",
    "# ax.plot(np.arange(max_error_weight+1) / n, synd_weight_min_avg / n, '--', color='gray')\n",
    "\n",
    "############################################################################################################\n",
    "# seperator between Laplacian and typical LDPC\n",
    "############################################################################################################\n",
    "\n",
    "readdir = '/Users/yitan/Google Drive/My Drive/from_cannon/qmemory_simulation/data/ldpc_code'\n",
    "deg_bit, deg_check = 4, 5\n",
    "noprledge = True\n",
    "\n",
    "size = 60\n",
    "n, m = deg_check*size, deg_bit*size\n",
    "error_weights_full = []\n",
    "synd_weights_min_full = []\n",
    "for seed in seeds:\n",
    "    readname = f'hclassical_config_model_nonlocal_n={n}_m={m}_deg_bit={deg_bit}_deg_check={deg_check}_noprledge={noprledge}_seed={seed}.txt'\n",
    "    h = read_pc(os.path.join(readdir, readname))\n",
    "    logical_basis = nullspace(h)\n",
    "    logical_ops = sample_logical_ops(logical_basis, nsamples_logical=1)\n",
    "    logical_op = logical_ops[0]\n",
    "    posones_logical = np.where(logical_op==1)[0]\n",
    "    # error_weights = np.arange(0, len(posones_logical)+1, 1)\n",
    "    error_weights = np.arange(0, int(truncate*n)+1, 1)\n",
    "    synd_weights_list = []\n",
    "    for error_weight in error_weights:\n",
    "        error_vecs = np.zeros((nsamples, h.shape[1]), dtype=int)\n",
    "        for i in range(nsamples):\n",
    "            posones_error = rng.choice(posones_logical, size=error_weight, replace=False)\n",
    "            error_vecs[i, posones_error] = 1\n",
    "        synd_vecs = np.mod(error_vecs@(h.T), 2)\n",
    "        synd_weights = np.sum(synd_vecs, axis=1)\n",
    "        synd_weights_list.append(synd_weights)\n",
    "    synd_weights_list = np.array(synd_weights_list)\n",
    "    synd_weights_min = np.min(synd_weights_list, axis=1)\n",
    "    # num_half = int(len(synd_weights_min)/2)\n",
    "    # error_weights = error_weights[:num_half]\n",
    "    # synd_weights_min = synd_weights_min[:num_half]\n",
    "    error_weights_full.append(error_weights)\n",
    "    synd_weights_min_full.append(synd_weights_min)\n",
    "max_error_weight = np.max([error_weights[-1] for error_weights in error_weights_full])\n",
    "synd_weight_min_avg = np.zeros(max_error_weight+1)\n",
    "for error_weight in range(max_error_weight+1):\n",
    "    nonzero_synd_weights = []\n",
    "    for i in range(len(seeds)):\n",
    "        if error_weight < len(error_weights_full[i]):\n",
    "            nonzero_synd_weights.append(synd_weights_min_full[i][error_weight])\n",
    "    synd_weight_min_avg[error_weight] = np.mean(nonzero_synd_weights)\n",
    "ax.scatter(np.arange(max_error_weight+1)[start:end:step] / n, synd_weight_min_avg[start:end:step] / m, c=blues_hex[-1], edgecolors='k', zorder=10)\n",
    "# ax.plot(np.arange(max_error_weight+1) / n, synd_weight_min_avg / m, '--', color='gray')\n",
    "\n",
    "\n",
    "\n",
    "size = 100\n",
    "n, m = deg_check*size, deg_bit*size\n",
    "error_weights_full = []\n",
    "synd_weights_min_full = []\n",
    "for seed in seeds:\n",
    "    readname = f'hclassical_config_model_nonlocal_n={n}_m={m}_deg_bit={deg_bit}_deg_check={deg_check}_noprledge={noprledge}_seed={seed}.txt'\n",
    "    h = read_pc(os.path.join(readdir, readname))\n",
    "    logical_basis = nullspace(h)\n",
    "    logical_ops = sample_logical_ops(logical_basis, nsamples_logical=1)\n",
    "    logical_op = logical_ops[0]\n",
    "    posones_logical = np.where(logical_op==1)[0]\n",
    "    # error_weights = np.arange(0, len(posones_logical)+1, 1)\n",
    "    error_weights = np.arange(0, int(truncate*n)+1, 1)\n",
    "    synd_weights_list = []\n",
    "    for error_weight in error_weights:\n",
    "        error_vecs = np.zeros((nsamples, h.shape[1]), dtype=int)\n",
    "        for i in range(nsamples):\n",
    "            posones_error = rng.choice(posones_logical, size=error_weight, replace=False)\n",
    "            error_vecs[i, posones_error] = 1\n",
    "        synd_vecs = np.mod(error_vecs@(h.T), 2)\n",
    "        synd_weights = np.sum(synd_vecs, axis=1)\n",
    "        synd_weights_list.append(synd_weights)\n",
    "    synd_weights_list = np.array(synd_weights_list)\n",
    "    synd_weights_min = np.min(synd_weights_list, axis=1)\n",
    "    # num_half = int(len(synd_weights_min)/2)\n",
    "    # error_weights = error_weights[:num_half]\n",
    "    # synd_weights_min = synd_weights_min[:num_half]\n",
    "    error_weights_full.append(error_weights)\n",
    "    synd_weights_min_full.append(synd_weights_min)\n",
    "max_error_weight = np.max([error_weights[-1] for error_weights in error_weights_full])\n",
    "synd_weight_min_avg = np.zeros(max_error_weight+1)\n",
    "for error_weight in range(max_error_weight+1):\n",
    "    nonzero_synd_weights = []\n",
    "    for i in range(len(seeds)):\n",
    "        if error_weight < len(error_weights_full[i]):\n",
    "            nonzero_synd_weights.append(synd_weights_min_full[i][error_weight])\n",
    "    synd_weight_min_avg[error_weight] = np.mean(nonzero_synd_weights)\n",
    "ax.scatter(np.arange(max_error_weight+1)[start:end:step] / n, synd_weight_min_avg[start:end:step] / m, c=blues_hex[-2], edgecolors='k', zorder=10)\n",
    "# ax2.plot(np.arange(max_error_weight+1) / n, synd_weight_min_avg / m, '--', color='gray')\n",
    "\n",
    "ax.set_xlim(0,0.22)\n",
    "ax.set_yticks([0, 0.1, 0.2, 0.3, 0.4])\n",
    "ax.set_xticks([0, 0.05, 0.1, 0.15, 0.2])\n",
    "fig.set_size_inches(5, 5)\n",
    "fig.savefig(f'../figures/laplacian_typical_ldpc_confinement_truncate.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qec_numerics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
